{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e894955a-e101-47db-bde1-1e08ea104a85",
   "metadata": {},
   "source": [
    "# Create a Cellpose model\n",
    "\n",
    "This is a program used to generate a new cellpose model based on a series of representative images and their corresponding manually labelled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c16d4-d2d7-4b6a-9679-d35d00fce944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cellpose import core, models, io, metrics\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tqdm \n",
    "import tifffile as tf\n",
    "\n",
    "import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb4444-cdc3-4c47-9e4e-97f3e4b77705",
   "metadata": {},
   "source": [
    "### set the Folder path for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2833fce-fdf8-433d-8cf6-bae62e3668d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.attributes(\"-topmost\", True)\n",
    "root.withdraw() # Stops a second window opening\n",
    "image_folder = filedialog.askdirectory(title = 'Select image Folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a8282-c862-4922-babd-bc6483ff3236",
   "metadata": {},
   "source": [
    "### Set the folder path for the user defined masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70550f82-8c6d-4722-bee4-a313c99a8b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.attributes(\"-topmost\", True)\n",
    "root.withdraw() # Stops a second window opening\n",
    "mask_folder = filedialog.askdirectory(title = 'Select Masks Folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205c4b4-a1da-4e34-bd9a-765dbacadc70",
   "metadata": {},
   "source": [
    "#### Create a method to extract all the filenames from a folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99500acf-d7d8-4ce1-b18a-53d0b613084e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_files_from_folder(folder_path): \n",
    "    '''A method to extract all files from the image.'''\n",
    "\n",
    "    file_list = os.listdir(folder_path)\n",
    "    image_files = []\n",
    "    \n",
    "    for i in range( len(file_list) ): \n",
    "        if file_list[i][-4:] == '.tif' or file_list[i][-4:] == '.png':\n",
    "            image_files.append(file_list[i])\n",
    "        \n",
    "    return(image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f19685-48ef-4a0f-ac5b-bac029ae70f7",
   "metadata": {},
   "source": [
    "#### Create a method to download in the image data from the image file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bdb4c1-abd0-4a8b-a57e-2a0af7370722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_data(image_file):\n",
    "    '''Get the image data from the file using Pillow.\n",
    "    Convert the PILLOW image to a numpy array'''\n",
    "\n",
    "    image_data = tf.imread(image_file)\n",
    "    \n",
    "    # print(image_data.getexif())\n",
    "    \n",
    "    np_image_data = np.array(image_data)\n",
    "\n",
    "    return(np_image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1237af7-06f0-42ff-ac68-4c00184b31fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_file_list = get_files_from_folder(image_folder)\n",
    "mask_file_list = get_files_from_folder(mask_folder)\n",
    "\n",
    "print( len(image_file_list) )\n",
    "print( len(mask_file_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8262e0-4ab9-4fb7-bcfc-efd6b5e4c818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(image_folder)\n",
    "print(mask_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ff93e-bd8f-44e2-a5ee-0a9e6a5c7a70",
   "metadata": {},
   "source": [
    "#### extract datasets for testing/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819862a3-0f01-43ad-a51c-5583c83a2a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_image_index = np.random.choice(len(image_file_list)-1, size = int(0.8*(len(image_file_list)-1)), replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec004d-8134-47bf-9e56-27a43ba590eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.sort(training_image_index))\n",
    "print(len(training_image_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a860fa5-60f2-475f-9fd8-905efde192ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_image_index = []\n",
    "\n",
    "for i in range(len(image_file_list)):\n",
    "    if len(np.where(training_image_index == i)[0]) == 0:\n",
    "        test_image_index.append(i)\n",
    "\n",
    "print(test_image_index)\n",
    "print(len(test_image_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05aee83-72d4-4b01-a53d-400332bf3c65",
   "metadata": {},
   "source": [
    "### Get test images and user_masks into a format for cellpose model Training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a267643-9643-4c1c-9e0d-c691cc59895e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_training = []\n",
    "training_images = []\n",
    "\n",
    "for i in range(len(training_image_index)):\n",
    "    # get the image data\n",
    "    image_file_name = image_file_list[training_image_index[i]]\n",
    "    individual_image = get_image_data(image_folder + '/'+ image_file_name)\n",
    "    training_images.append(individual_image)\n",
    "    # get the corresponding user_defined_mask\n",
    "    mask_file_name = image_file_name[0:-4] + '.tif'\n",
    "    # print(image_file_name)\n",
    "    # print(mask_file_name)\n",
    "    user_mask = get_image_data(mask_folder + '/'+ mask_file_name)\n",
    "    ground_truth_training.append(user_mask)\n",
    "\n",
    "    \n",
    "# ground_truth = np.array(ground_truth)\n",
    "print(training_images[0].shape)\n",
    "print(ground_truth_training[0].shape)\n",
    "print(len(training_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfed344-8d9a-4e10-a5f9-0908a7373e06",
   "metadata": {},
   "source": [
    "### Get test images and user_masks into a format for cellpose model evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356245ad-eb05-456a-83f7-5611ac05c521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_test = []\n",
    "test_images = []\n",
    "\n",
    "for i in range(len(test_image_index)):\n",
    "    # get the image data\n",
    "    image_file_name = image_file_list[test_image_index[i]]\n",
    "    individual_image = get_image_data(image_folder + '/'+ image_file_name)\n",
    "    test_images.append(individual_image)\n",
    "    # get the corresponding user_defined_mask\n",
    "    mask_file_name = image_file_name[0:-4] + '.tif'\n",
    "    # print(image_file_name)\n",
    "    # print(mask_file_name)\n",
    "    user_mask = get_image_data(mask_folder + '/'+ mask_file_name)\n",
    "    ground_truth_test.append(user_mask)\n",
    "\n",
    "    \n",
    "# ground_truth = np.array(ground_truth)\n",
    "print(test_images[i].shape)\n",
    "print(ground_truth_test[i].shape)\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ca6b2-5ca1-4192-8f59-8a0ba40d6c5c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train a model using the training data provided to the program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7abc37-dd35-4822-a899-d064134a2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_and_time():\n",
    "    '''Get the time and date at this moment in time.'''\n",
    "\n",
    "    # Get the current time and date.\n",
    "    date_time_now = str(datetime.datetime.now())\n",
    "\n",
    "    # Extract the date. \n",
    "    date = date_time_now[0:10]\n",
    "    date = date.replace('-', '_')\n",
    "    \n",
    "    # Extract the time\n",
    "    find_colon = date_time_now.find(':')\n",
    "    find_dp = date_time_now.find('.')\n",
    "    time = date_time_now[find_colon-2:find_dp]\n",
    "    \n",
    "    time = time.replace(':', '_')\n",
    "\n",
    "    return(date, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6d0c8-a89b-487d-8824-7f4babd87012",
   "metadata": {},
   "source": [
    "----\n",
    "The next cell performs the training of cellpose models. The code is taken directly from a google colaboratry notebook, produced by the research group behind cellpose, avaliable at the following location: https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/run_cellpose_2.ipynb\n",
    "\n",
    "For more information about github, please see:     \n",
    "Paper: https://www.nature.com/articles/s41592-022-01663-4   \n",
    "Online documentation: https://cellpose.readthedocs.io/en/latest/   \n",
    "Github Repository: https://github.com/MouseLand/cellpose/tree/main   \n",
    "\n",
    "Reference:   \n",
    "Pachitariu, M., Stringer, C. Cellpose 2.0: how to train your own model. Nat Methods 19, 1634â€“1641 (2022). https://doi.org/10.1038/s41592-022-01663-4\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19b2d0-43fa-47ca-bbbc-a649493df1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is taken directly from the Colab notebook and then \n",
    "# modified for my needs. \n",
    "\n",
    "# Get the date and time. \n",
    "date, time = get_date_and_time()\n",
    "\n",
    "# start logger (to see training across epochs)\n",
    "logger = io.logger_setup()\n",
    "\n",
    "# DEFINE CELLPOSE MODEL (without size model)\n",
    "model = models.CellposeModel(gpu=True, model_type='cyto')\n",
    "\n",
    "# set channels\n",
    "channels = [0, 0]\n",
    "# Set Epoch to train over\n",
    "n_epochs = 100\n",
    "# Set learning rate. \n",
    "learning_rate = 0.1\n",
    "# Set the weight decay\n",
    "weight_decay = 0.0001\n",
    "\n",
    "\n",
    "# # get files\n",
    "# output = io.load_train_test_data(train_dir, test_dir, mask_filter='_seg.npy')\n",
    "# # train_data, train_labels, _, test_data, test_labels, _ = output\n",
    "\n",
    "new_model_path = model.train(training_images[0 : int(0.8*len(training_images)) ], ground_truth_training[0 : int( 0.8*len(training_images)) ], \n",
    "                              test_data=training_images[int(0.8*len(training_images)):],\n",
    "                              test_labels=ground_truth_training[int(0.8*len(training_images)):],\n",
    "                              channels=channels, \n",
    "                              save_path=os.path.dirname(image_folder), \n",
    "                              n_epochs=n_epochs,\n",
    "                              learning_rate=learning_rate, \n",
    "                              weight_decay=weight_decay, \n",
    "                              nimg_per_epoch=8,\n",
    "                              model_name = date + '_' + time +'_' + 'CP_Models')\n",
    "\n",
    "# diameter of labels in training images\n",
    "diam_labels = model.diam_labels.copy()\n",
    "\n",
    "print(test_images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765185e-3936-4cea-b509-47ffcbe2c68d",
   "metadata": {},
   "source": [
    "---------\n",
    "## Test Accuracy of newly generated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0769d-dd45-4530-af46-0c48c8db4d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initalise\n",
    "retrained_masks = []\n",
    "\n",
    "#########\n",
    "## NOTE: Need to manually add new cellpose model to path, see following link: \n",
    "## https://cellpose.readthedocs.io/en/latest/models.html#user-trained-models\n",
    "#########\n",
    "\n",
    "# Add path to cellpose model/cellpose model name. \n",
    "model_path = date + '_' + time +'_' + 'CP_Models'\n",
    "\n",
    "# initalise model\n",
    "model = models.CellposeModel(gpu=True, model_type=model_path)\n",
    "\n",
    "# For all of the testing images.  \n",
    "for i in tqdm.tqdm(range(len(test_images) )):\n",
    "    print(test_images[i].shape)\n",
    "    masks = model.eval(test_images[i], channels = [2, 0], diameter = None)[0]\n",
    "    retrained_masks.append(masks)\n",
    "\n",
    "# Check the performance of the model using IoU metric. \n",
    "ap = metrics.average_precision(ground_truth_test, retrained_masks)[0]\n",
    "# Print the model accuracy. \n",
    "print(ap[:,0].mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f8980-3d56-43f2-97f1-5808e08875a1",
   "metadata": {},
   "source": [
    "----------\n",
    "### Plot the cellpose masks and the ground truth to compare results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f7969-9ee5-4d86-a14f-8ad3ab50381b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im = 1\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.imshow(test_images[im][ :, :], vmin = 50)\n",
    "ax1.imshow(retrained_masks[im], alpha = 0.25, cmap = 'inferno_r', vmax = 1)\n",
    "ax1.set_title('Cellpose Masks')\n",
    "\n",
    "fig3, ax3 = plt.subplots()\n",
    "ax3.imshow(test_images[im][ :, :], vmin = 50)\n",
    "ax3.imshow(ground_truth_test[im], alpha = 0.25, cmap = 'inferno_r', vmax = 1)\n",
    "ax3.set_title('Ground truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01cf911-c7c8-442c-9e1c-e470fc4b59aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
